{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "Dataset sizes:\n",
      "Training set: 12948 samples\n",
      "Validation set: 1396 samples\n",
      "Test set: 2699 samples\n",
      "\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pratham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set Performance:\n",
      "Accuracy: 0.7142\n",
      "F1 Score: 0.3677\n",
      "AUC-ROC: 0.6715\n",
      "F1 Score (Truth Class): 0.8154\n",
      "F1 Score (Lie Class): 0.3677\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.82      1008\n",
      "           1       0.48      0.30      0.37       388\n",
      "\n",
      "    accuracy                           0.71      1396\n",
      "   macro avg       0.62      0.59      0.59      1396\n",
      "weighted avg       0.68      0.71      0.69      1396\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.5517\n",
      "F1 Score: 0.4988\n",
      "AUC-ROC: 0.6323\n",
      "F1 Score (Truth Class): 0.5945\n",
      "F1 Score (Lie Class): 0.4988\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.48      0.59      1865\n",
      "           1       0.38      0.72      0.50       834\n",
      "\n",
      "    accuracy                           0.55      2699\n",
      "   macro avg       0.59      0.60      0.55      2699\n",
      "weighted avg       0.67      0.55      0.56      2699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load data from JSONL file\"\"\"\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        return [json.loads(line) for line in file]\n",
    "\n",
    "def diplomacy_tokenizer(text):\n",
    "    \"\"\"Custom tokenizer for Diplomacy game messages\"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Handle emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                           u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r' emoji ', text)\n",
    "    \n",
    "    # Handle territory names\n",
    "    territory_names = ['marseille', 'iberia', 'brest', 'paris', 'tyrolia', 'trieste', 'burgundy', \n",
    "                      'mediterranean', 'adriatic', 'aegean', 'english channel', 'baltic', 'north sea',\n",
    "                      'western mediterranean', 'eastern mediterranean', 'ionian sea', 'tyrrhenian sea']\n",
    "    for territory in territory_names:\n",
    "        text = text.replace(territory, f\"TERRITORY_{territory.replace(' ', '_')}\")\n",
    "    \n",
    "    # Handle game terms\n",
    "    game_terms = ['attack', 'defend', 'support', 'convoy', 'build', 'retreat', 'disband', \n",
    "                 'hold', 'move', 'bounce', 'cut', 'dislodge', 'alliance', 'truce']\n",
    "    for term in game_terms:\n",
    "        text = text.replace(term, f\"GAMETERM_{term}\")\n",
    "    \n",
    "    return re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "def extract_harbinger_features(message):\n",
    "    \"\"\"Extract linguistic features from messages\"\"\"\n",
    "    message_lower = message.lower()\n",
    "    \n",
    "    features = {\n",
    "        # Politeness\n",
    "        'has_please': 'please' in message_lower,\n",
    "        'has_thanks': any(word in message_lower for word in ['thanks', 'thank you', 'appreciate']),\n",
    "        'has_sorry': any(word in message_lower for word in ['sorry', 'apologies', 'apologize', 'my bad']),\n",
    "        \n",
    "        # Alignment\n",
    "        'mentions_we': any(word in message_lower.split() for word in ['we', 'us', 'our', 'together', 'both']),\n",
    "        'mentions_you': any(word in message_lower.split() for word in ['you', 'your', 'yours']),\n",
    "        'mentions_i': any(word in message_lower.split() for word in ['i', 'me', 'my', 'mine']),\n",
    "        \n",
    "        # Engagement\n",
    "        'asks_question': '?' in message,\n",
    "        'uses_exclamation': '!' in message,\n",
    "        'message_length': len(message),\n",
    "        'avg_word_length': np.mean([len(word) for word in message_lower.split()]) if message_lower.split() else 0,\n",
    "        \n",
    "        # Emotion/Certainty\n",
    "        'has_emoji': bool(re.search(r'[\\U0001F000-\\U0001FFFF]', message)),\n",
    "        'uses_hedging': any(word in message_lower for word in ['maybe', 'perhaps', 'possibly', 'might', 'could', 'would', 'should']),\n",
    "        'uses_certainty': any(word in message_lower for word in ['definitely', 'certainly', 'absolutely', 'surely', 'will', 'must']),\n",
    "        'expresses_positive': any(word in message_lower for word in ['good', 'great', 'excellent', 'awesome', 'fantastic', 'wonderful', 'perfect', 'happy']),\n",
    "        'expresses_negative': any(word in message_lower for word in ['bad', 'terrible', 'awful', 'unfortunate', 'sad', 'unhappy', 'sorry', 'worry']),\n",
    "        \n",
    "        # Strategy/Deception\n",
    "        'mentions_attack': any(word in message_lower for word in ['attack', 'invade', 'move', 'capture', 'take']),\n",
    "        'mentions_defense': any(word in message_lower for word in ['defend', 'hold', 'protect', 'support', 'cover']),\n",
    "        'mentions_alliance': any(word in message_lower for word in ['ally', 'alliance', 'together', 'support', 'help', 'cooperate', 'friend']),\n",
    "        'mentions_betrayal': any(word in message_lower for word in ['betray', 'lie', 'cheat', 'backstab', 'break']),\n",
    "        'future_planning': any(word in message_lower for word in ['plan', 'future', 'next', 'later', 'after', 'then', 'will']),\n",
    "        'offers_deal': any(word in message_lower for word in ['deal', 'offer', 'agreement', 'compromise', 'exchange']),\n",
    "        'uses_justification': any(word in message_lower for word in ['because', 'since', 'reason', 'explain', 'understand']),\n",
    "        'expresses_concern': any(word in message_lower for word in ['concern', 'worried', 'scared', 'afraid', 'fear']),\n",
    "        \n",
    "        # Game references\n",
    "        'mentions_territory': any(word in message_lower for word in ['marseille', 'iberia', 'brest', 'paris', 'tyrolia', 'trieste', 'burgundy', 'mediterranean']),\n",
    "        'mentions_country': any(word in message_lower for word in ['france', 'germany', 'italy', 'england', 'austria', 'russia', 'turkey']),\n",
    "        'mentions_season': any(word in message_lower for word in ['spring', 'fall', 'winter', 'year']),\n",
    "        'mentions_unit': any(word in message_lower for word in ['fleet', 'army', 'unit', 'forces', 'troops']),\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "def preprocess_diplomacy_data(data):\n",
    "    \"\"\"Process raw game data into features and labels\"\"\"\n",
    "    all_messages = []\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for game in data:\n",
    "        messages = game.get(\"messages\", [])\n",
    "        sender_labels = game.get(\"sender_labels\", [])\n",
    "        receiver_labels = game.get(\"receiver_labels\", [])\n",
    "        speakers = game.get(\"speakers\", [])\n",
    "        receivers = game.get(\"receivers\", [])\n",
    "        seasons = game.get(\"seasons\", [])\n",
    "        years = game.get(\"years\", [])\n",
    "        game_score = game.get(\"game_score\", [])\n",
    "        game_score_delta = game.get(\"game_score_delta\", [])\n",
    "        game_id = game.get(\"game_id\", \"\")\n",
    "        \n",
    "        if not messages or len(messages) < 2:\n",
    "            continue\n",
    "        \n",
    "        for i in range(len(messages) - 1):\n",
    "            message = messages[i]\n",
    "            \n",
    "            base_features = {\n",
    "                'game_id': game_id,\n",
    "                'sender': speakers[i] if i < len(speakers) else \"\",\n",
    "                'receiver': receivers[i] if i < len(receivers) else \"\",\n",
    "                'season': seasons[i] if i < len(seasons) else \"\",\n",
    "                'year': years[i] if i < len(years) else \"\",\n",
    "                'current_score': int(game_score[i]) if i < len(game_score) else 0,\n",
    "                'is_sender_player': sender_labels[i] if i < len(sender_labels) else False,\n",
    "                'is_receiver_player': receiver_labels[i] if i < len(receiver_labels) else False,\n",
    "                'message_index': i,\n",
    "                'total_messages': len(messages),\n",
    "                'relative_position': i / len(messages) if messages else 0,\n",
    "            }\n",
    "            \n",
    "            next_score_delta = int(game_score_delta[i+1]) if i+1 < len(game_score_delta) else 0\n",
    "            harbinger_features = extract_harbinger_features(message)\n",
    "            combined_features = {**base_features, **harbinger_features}\n",
    "            label = 1 if next_score_delta < 0 else 0\n",
    "            \n",
    "            all_messages.append(message)\n",
    "            all_features.append(combined_features)\n",
    "            all_labels.append(label)\n",
    "    \n",
    "    return all_messages, pd.DataFrame(all_features), all_labels\n",
    "\n",
    "def print_metrics(true_labels, predictions, probabilities, set_name):\n",
    "    \"\"\"Print evaluation metrics for a dataset\"\"\"\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    auc = roc_auc_score(true_labels, probabilities)\n",
    "    \n",
    "    print(f\"\\n{set_name} Set Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    \n",
    "    report = classification_report(true_labels, predictions, output_dict=True)\n",
    "    print(f\"F1 Score (Truth Class): {report['0']['f1-score']:.4f}\")\n",
    "    print(f\"F1 Score (Lie Class): {report['1']['f1-score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, predictions))\n",
    "\n",
    "def main():\n",
    "    # Load datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    train_data = load_jsonl(r\"C:\\Users\\pratham\\Downloads\\train.jsonl\")\n",
    "    val_data = load_jsonl(r\"C:\\Users\\pratham\\Downloads\\validation.jsonl\")\n",
    "    test_data = load_jsonl(r\"C:\\Users\\pratham\\Downloads\\test.jsonl\")\n",
    "    \n",
    "    # Preprocess data\n",
    "    print(\"\\nPreprocessing data...\")\n",
    "    train_messages, train_features, train_labels = preprocess_diplomacy_data(train_data)\n",
    "    val_messages, val_features, val_labels = preprocess_diplomacy_data(val_data)\n",
    "    test_messages, test_features, test_labels = preprocess_diplomacy_data(test_data)\n",
    "    \n",
    "    print(f\"\\nDataset sizes:\")\n",
    "    print(f\"Training set: {len(train_messages)} samples\")\n",
    "    print(f\"Validation set: {len(val_messages)} samples\")\n",
    "    print(f\"Test set: {len(test_messages)} samples\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train = pd.concat([train_features, pd.Series(train_messages, name='message')], axis=1)\n",
    "    X_val = pd.concat([val_features, pd.Series(val_messages, name='message')], axis=1)\n",
    "    X_test = pd.concat([test_features, pd.Series(test_messages, name='message')], axis=1)\n",
    "    y_train, y_val, y_test = train_labels, val_labels, test_labels\n",
    "    \n",
    "    # Define preprocessing\n",
    "    categorical_features = ['sender', 'receiver', 'season', 'year']\n",
    "    numeric_features = [col for col in train_features.columns if train_features[col].dtype in [np.int64, np.float64]]\n",
    "    boolean_features = [col for col in train_features.columns if train_features[col].dtype == bool]\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('bool', 'passthrough', boolean_features),\n",
    "            ('txt', TfidfVectorizer(\n",
    "                max_features=500, \n",
    "                ngram_range=(1, 3),\n",
    "                tokenizer=diplomacy_tokenizer,\n",
    "                min_df=3\n",
    "            ), 'message')\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "    \n",
    "    # Build pipeline\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(\n",
    "            C=1.0,\n",
    "            class_weight='balanced',\n",
    "            max_iter=1000,\n",
    "            random_state=42,\n",
    "            solver='liblinear'\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nTraining model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    for X, y, name in [(X_val, y_val, \"Validation\"), (X_test, y_test, \"Test\")]:\n",
    "        preds = model.predict(X)\n",
    "        probs = model.predict_proba(X)[:, 1]\n",
    "        print_metrics(y, preds, probs, name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
